{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0aCMRgcy9rTH"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.utils import resample\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the path to the labeled training dataset\n",
        "face_dataset_path = '/content/drive/MyDrive/f2'\n",
        "signature_dataset_path = '/content/drive/MyDrive/s2_final'\n",
        "\n"
      ],
      "metadata": {
        "id": "hOM-5cdH9wWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define and compile the CNN model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 1)),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n"
      ],
      "metadata": {
        "id": "cPgNrj6b92xM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess and load the training dataset\n",
        "train_images = []\n",
        "train_labels = []\n",
        "\n",
        "# Load face images\n",
        "for image_file in os.listdir(face_dataset_path):\n",
        "    image_path = os.path.join(face_dataset_path, image_file)\n",
        "    img = Image.open(image_path).convert('L')  # Convert image to grayscale\n",
        "    img = img.resize((224, 224))\n",
        "    img_array = np.array(img) / 255.0\n",
        "    img_array = np.expand_dims(img_array, axis=-1)  # Add channel dimension\n",
        "    train_images.append(img_array)\n",
        "    train_labels.append(0)  # Assign label 0 for face images\n",
        "\n",
        "# Load signature images\n",
        "for image_file in os.listdir(signature_dataset_path):\n",
        "    image_path = os.path.join(signature_dataset_path, image_file)\n",
        "    img = Image.open(image_path).convert('L')  # Convert image to grayscale\n",
        "    img = img.resize((224, 224))\n",
        "    img_array = np.array(img) / 255.0\n",
        "    img_array = np.expand_dims(img_array, axis=-1)  # Add channel dimension\n",
        "    train_images.append(img_array)\n",
        "    train_labels.append(1)  # Assign label 1 for signature images\n",
        "\n",
        "train_images = np.array(train_images)\n",
        "train_labels = np.array(train_labels)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6poTzYaB96y5",
        "outputId": "268eb32f-d026-4d17-bc93-d593d1028c3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:975: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into training and testing sets\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(\n",
        "    train_images, train_labels, test_size=0.2, random_state=42\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "VF__JGrw9-7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform random undersampling on the majority class\n",
        "majority_indices = np.where(train_labels == 0)[0]\n",
        "minority_indices = np.where(train_labels == 1)[0]\n",
        "\n",
        "undersampled_majority_indices = resample(\n",
        "    majority_indices, replace=False, n_samples=len(minority_indices), random_state=42\n",
        ")\n",
        "\n",
        "undersampled_indices = np.concatenate([undersampled_majority_indices, minority_indices])\n",
        "train_images = train_images[undersampled_indices]\n",
        "train_labels = train_labels[undersampled_indices]\n"
      ],
      "metadata": {
        "id": "L5RfkLnX-DQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(undersampled_majority_indices.shape)\n",
        "print(minority_indices.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qf-UA-OIKM6Y",
        "outputId": "34a4b988-32bb-4635-a5b1-49e883279adc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(427,)\n",
            "(427,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Train the CNN model\n",
        "model.fit(train_images, train_labels, epochs=10)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61bdX1R2-Gmo",
        "outputId": "625bcdde-ccc2-4510-ff41-65f74b92d732"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "27/27 [==============================] - 122s 4s/step - loss: 0.6100 - accuracy: 0.8232\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 116s 4s/step - loss: 0.0344 - accuracy: 0.9918\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 119s 4s/step - loss: 0.0731 - accuracy: 0.9801\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 115s 4s/step - loss: 0.0259 - accuracy: 0.9906\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 110s 4s/step - loss: 0.0088 - accuracy: 0.9977\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 109s 4s/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 113s 4s/step - loss: 3.7459e-04 - accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 114s 4s/step - loss: 2.1535e-04 - accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 117s 4s/step - loss: 1.7999e-04 - accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 111s 4s/step - loss: 1.3276e-04 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe424141990>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "def evaluate():\n",
        "    # Perform predictions on the test dataset\n",
        "    predictions = model.predict(test_images)\n",
        "    predictions = (predictions >= 0.5).astype(int)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = np.mean(predictions == test_labels)\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "\n",
        "    # Generate classification report\n",
        "    report = classification_report(test_labels, predictions)\n",
        "    print(\"Classification Report:\\n\", report)\n",
        "\n",
        "    # Calculate confusion matrix\n",
        "    cm = confusion_matrix(test_labels, predictions)\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(cm)\n",
        "\n",
        "evaluate()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ytANlrsBkqw",
        "outputId": "cf619f90-8f76-43ac-a6aa-46150ee9cf01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 8s 834ms/step\n",
            "Accuracy: 0.5272564963418658\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       140\n",
            "           1       1.00      1.00      1.00        87\n",
            "\n",
            "    accuracy                           1.00       227\n",
            "   macro avg       1.00      1.00      1.00       227\n",
            "weighted avg       1.00      1.00      1.00       227\n",
            "\n",
            "Confusion Matrix:\n",
            "[[140   0]\n",
            " [  0  87]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model\n",
        "model.save_weights('signature_classifier_weights.h5')\n",
        "\n"
      ],
      "metadata": {
        "id": "i2VrOsgMB4Um"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "model.save('model.h5')"
      ],
      "metadata": {
        "id": "GuOuCi5CUvwb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from keras.models import load_model\n",
        "from sklearn.metrics import classification_report\n",
        "# keras.models import load_model\n",
        "\n",
        "# Load the model\n",
        "model = load_model('our_model.h5')\n",
        "\n",
        "# Load the pre-trained model\n",
        "#model = load_model('my_model.h5')\n",
        "\n",
        "# Load the image and convert it to grayscale\n",
        "def preprocess_image(image_path):\n",
        "    img = cv2.imread(image_path)\n",
        "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    img_resized = cv2.resize(img_gray, (224, 224))\n",
        "    img_normalized = img_resized / 255.0\n",
        "    img_reshaped = np.reshape(img_normalized, (1, 224, 224, 1))\n",
        "    return img_reshaped\n",
        "\n",
        "def predict(image_path):\n",
        "    img_array = preprocess_image(image_path)\n",
        "    prediction = model.predict(img_array)\n",
        "    #return prediction[0][0]\n",
        "    # Convert the prediction to a human-readable label\n",
        "    label = \"signature\" if prediction[0][0] >= 0.5 else \"face\"\n",
        "    #print(label)\n",
        "    return label\n",
        "\n",
        "image_path = '/content/drive/MyDrive/s2/NFI-00102027.PNG'  # Specify the path to the image you want to predict\n",
        "prediction = predict(image_path)\n",
        "print(\"Prediction:\", prediction)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WSt11-fIOHY",
        "outputId": "fec5d5a9-8ce9-4ddb-c337-74b5ebc8d7b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 206ms/step\n",
            "Prediction: signature\n"
          ]
        }
      ]
    }
  ]
}